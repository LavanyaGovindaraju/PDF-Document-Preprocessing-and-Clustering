{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce08a2d",
   "metadata": {},
   "source": [
    "## PDF Document Partitioning\n",
    "\n",
    "Objective:\n",
    "Implement the `partition_the_pdf_document` function to analyze a PDF file and identify groups of pages that belong together as distinct documents or sections.\n",
    "\n",
    "Code Structure:\n",
    "The function `partition_the_pdf_document` is provided with a basic structure. Your task is to implement the logic within this function.\n",
    "\n",
    "Input:\n",
    "- A PDF file path (the function should be able to handle various PDF files)\n",
    "\n",
    "Output:\n",
    "- A dictionary where:\n",
    "  - Keys are strings representing document names (e.g., \"Document 1\", \"Document 2\", etc.)\n",
    "  - Values are lists of integers representing page numbers belonging to each document\n",
    "\n",
    "Task:\n",
    "1. Implement the `partition_the_pdf_document` function:\n",
    "   - Input: A string representing the path to the input PDF file\n",
    "   - Output: A dictionary of document groups as described above\n",
    "\n",
    "2. The function should analyze the content and visual features of the PDF to determine logical groupings of pages.\n",
    "\n",
    "Requirements:\n",
    "1. The function must be generalizable to work with different PDF files, not just the example \"grouped_documents.pdf\".\n",
    "2. Implement robust methods to detect various visual features that might distinguish different documents within the PDF, such as:\n",
    "   - Colored borders\n",
    "   - Watermarks\n",
    "   - Colored backgrounds\n",
    "   - Distinctive headers or footers\n",
    "   - Changes in layout or formatting\n",
    "3. Handle potential exceptions or edge cases (e.g., inconsistent formatting, mixed feature types).\n",
    "4. Optimize for both accuracy and processing speed, considering that PDFs can be large and contain many pages.\n",
    "5. You are allowed to use up to 40GB of GPU VRAM if necessary for your implementation.\n",
    "\n",
    "Additional Considerations:\n",
    "- You may use additional libraries if needed, but ensure they are imported properly.\n",
    "- You can create additional helper functions as necessary to support your implementation.\n",
    "- Provide clear comments in your code to explain your partitioning logic.\n",
    "\n",
    "Testing:\n",
    "- Test your implementation with various types of PDFs to ensure its robustness and generalizability.\n",
    "- The main script provides a way to test your implementation on a file named \"grouped_documents.pdf\".\n",
    "\n",
    "Note:\n",
    "The example output in the provided code is specific to \"grouped_documents.pdf\". Your implementation should be able to handle different PDFs with varying numbers of documents and pages per document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec316d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters: 6\n",
      "Partitions: {'Document 6': [1], 'Document 5': [2, 3], 'Document 4': [4, 5, 6, 16, 17, 18], 'Document 3': [7, 8, 9], 'Document 1': [10, 11, 12], 'Document 2': [13, 14, 15]}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not find the number of physical cores for the following reason:\")\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "def get_color_feature(item: Dict[str, Any]) -> Tuple[int, int, int]:\n",
    "    \"\"\"\n",
    "    Get the color feature from a drawing item.\n",
    "\n",
    "    Args:\n",
    "        item (Dict[str, Any]): The drawing item.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[int, int, int]: The color feature as an RGB tuple.\n",
    "    \"\"\"\n",
    "    color = item.get('color', (0, 0, 0))\n",
    "    if color is None or not isinstance(color, tuple):\n",
    "        return (0, 0, 0)\n",
    "    return color\n",
    "\n",
    "def normalize_color(color: Tuple[int, int, int]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Normalize color values to the range [0, 1].\n",
    "\n",
    "    Args:\n",
    "        color (Tuple[int, int, int]): The color to normalize.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: The normalized color values.\n",
    "    \"\"\"\n",
    "    return [c / 255.0 for c in color]\n",
    "\n",
    "def extract_text_and_color(blocks: List[Dict[str, Any]], page_height: float) -> Tuple[str, Tuple[int, int, int], str, Tuple[int, int, int]]:\n",
    "    \"\"\"\n",
    "    Extract text and color information from header and footer.\n",
    "\n",
    "    Args:\n",
    "        blocks (List[Dict[str, Any]]): The text blocks.\n",
    "        page_height (float): The height of the page.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, Tuple[int, int, int], str, Tuple[int, int, int]]: Header text and color, footer text and color.\n",
    "    \"\"\"\n",
    "    header_text = ''\n",
    "    header_color = (255, 255, 255)\n",
    "    footer_text = ''\n",
    "    footer_color = (255, 255, 255)\n",
    "\n",
    "    for block in blocks:\n",
    "        if \"lines\" in block:\n",
    "            if block[\"bbox\"][1] < 0.1 * page_height and block[\"lines\"]:\n",
    "                header_text = block[\"lines\"][0][\"spans\"][0][\"text\"] if block[\"lines\"][0][\"spans\"] else ''\n",
    "                if block[\"lines\"][0][\"spans\"]:\n",
    "                    header_color = get_color_feature(block[\"lines\"][0][\"spans\"][0])\n",
    "            if block[\"bbox\"][3] > 0.9 * page_height and block[\"lines\"]:\n",
    "                footer_text = block[\"lines\"][0][\"spans\"][0][\"text\"] if block[\"lines\"][0][\"spans\"] else ''\n",
    "                if block[\"lines\"][0][\"spans\"]:\n",
    "                    footer_color = get_color_feature(block[\"lines\"][0][\"spans\"][0])\n",
    "\n",
    "    return header_text, header_color, footer_text, footer_color\n",
    "\n",
    "def get_background_color(page: fitz.Page) -> Tuple[int, int, int]:\n",
    "    \"\"\"\n",
    "    Get the background color of a PDF page.\n",
    "\n",
    "    Args:\n",
    "        page (fitz.Page): The PDF page.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[int, int, int]: The background color as an RGB tuple.\n",
    "    \"\"\"\n",
    "    # Convert the page to an image\n",
    "    pix = page.get_pixmap(alpha=False)\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    \n",
    "    # Convert image to numpy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Flatten the image array\n",
    "    pixels = img_array.reshape(-1, 3)\n",
    "    \n",
    "    # Create a histogram of colors\n",
    "    hist, _ = np.histogramdd(pixels, bins=(256, 256, 256))\n",
    "    \n",
    "    # Find the most common color\n",
    "    index = np.unravel_index(hist.argmax(), hist.shape)\n",
    "    bg_color = tuple(index)\n",
    "    \n",
    "    # If the background is very light (close to white), perform additional analysis\n",
    "    if np.mean(bg_color) > 240:\n",
    "        # Calculate the standard deviation of each color channel\n",
    "        std_dev = np.std(pixels, axis=0)\n",
    "        \n",
    "        # If there's significant variation, use a more detailed analysis\n",
    "        if np.max(std_dev) > 10:\n",
    "            # Create a mask for non-white pixels\n",
    "            non_white_mask = np.any(pixels < 240, axis=1)\n",
    "            non_white_pixels = pixels[non_white_mask]\n",
    "            \n",
    "            if len(non_white_pixels) > 0:\n",
    "                # Calculate the mean of non-white pixels\n",
    "                bg_color = tuple(np.mean(non_white_pixels, axis=0).astype(int))\n",
    "    \n",
    "    return bg_color\n",
    "\n",
    "def get_visual_features(page: fitz.Page) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract detailed visual features from a PDF page.\n",
    "\n",
    "    Args:\n",
    "        page (fitz.Page): A single page from a PDF.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: A dictionary of visual features.\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        'border_color': (0, 0, 0),\n",
    "        'watermark_text': '',\n",
    "        'background_color': (255, 255, 255),\n",
    "        'header_text': '',\n",
    "        'header_color': (255, 255, 255),\n",
    "        'footer_text': '',\n",
    "        'footer_color': (255, 255, 255),\n",
    "        'layout_complexity': 0\n",
    "    }\n",
    "\n",
    "    # Analyze for colored borders\n",
    "    drawings = page.get_drawings()\n",
    "    for item in drawings:\n",
    "        color = item.get('color')\n",
    "        if color is not None and isinstance(color, tuple):\n",
    "            features['border_color'] = get_color_feature(item)\n",
    "            break\n",
    "\n",
    "    # Analyze for watermarks\n",
    "    text = page.get_text(\"text\")\n",
    "    watermark_matches = re.findall(r'watermark', text, re.IGNORECASE)\n",
    "    features['watermark_text'] = \" \".join(watermark_matches)\n",
    "\n",
    "    # Extract background color\n",
    "    features['background_color'] = get_background_color(page)\n",
    "\n",
    "    # Analyze headers and footers\n",
    "    blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "    page_height = page.rect.height\n",
    "    header_text, header_color, footer_text, footer_color = extract_text_and_color(blocks, page_height)\n",
    "    features['header_text'] = header_text\n",
    "    features['header_color'] = header_color\n",
    "    features['footer_text'] = footer_text\n",
    "    features['footer_color'] = footer_color\n",
    "\n",
    "    # Layout analysis (simple example based on number of text blocks)\n",
    "    features['layout_complexity'] = len(blocks)\n",
    "\n",
    "    return features\n",
    "\n",
    "def feature_vectorize(features: Dict[str, Any], vectorizer: TfidfVectorizer) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert feature dictionary to a numerical vector for clustering.\n",
    "\n",
    "    Args:\n",
    "        features (Dict[str, Any]): A dictionary of visual features.\n",
    "        vectorizer (TfidfVectorizer): A TfidfVectorizer for transforming textual features.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A numerical vector representation of the features.\n",
    "    \"\"\"\n",
    "    text_features = [features['header_text'], features['footer_text'], features['watermark_text']]\n",
    "    text_vector = vectorizer.transform([\" \".join(text_features)]).toarray().flatten()\n",
    "\n",
    "    color_vector = np.array([\n",
    "        *normalize_color(features['border_color']),\n",
    "        *normalize_color(features['background_color']),\n",
    "        *normalize_color(features['header_color']),\n",
    "        *normalize_color(features['footer_color'])\n",
    "    ], dtype=float)\n",
    "\n",
    "    layout_vector = np.array([\n",
    "        features['layout_complexity']\n",
    "    ], dtype=float)\n",
    "\n",
    "    return np.concatenate([color_vector, layout_vector, text_vector])\n",
    "\n",
    "def determine_optimal_clusters(feature_vectors: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Determine the optimal number of clusters using the Elbow Method.\n",
    "\n",
    "    Args:\n",
    "        feature_vectors (np.ndarray): The feature vectors for clustering.\n",
    "\n",
    "    Returns:\n",
    "        int: The optimal number of clusters.\n",
    "    \"\"\"\n",
    "    max_clusters = min(10, len(feature_vectors))  # Set upper limit for clusters\n",
    "    distortions = []\n",
    "    silhouette_scores = []\n",
    "    K = range(2, max_clusters + 1)\n",
    "\n",
    "    for k in K:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0, n_init=10, max_iter=100)\n",
    "        kmeans.fit(feature_vectors)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "        silhouette_scores.append(silhouette_score(feature_vectors, kmeans.labels_))\n",
    "\n",
    "    # Use silhouette score to determine the best number of clusters\n",
    "    optimal_k = K[np.argmax(silhouette_scores)]\n",
    "    return optimal_k\n",
    "\n",
    "def save_features_to_csv(features_list: List[Dict[str, Any]], filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Save the features of each page to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        features_list (List[Dict[str, Any]]): A list of feature dictionaries for each page.\n",
    "        filename (str): The name of the CSV file to save the features.\n",
    "    \"\"\"\n",
    "    keys = features_list[0].keys()\n",
    "    with open(filename, 'w', newline='') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(features_list)\n",
    "\n",
    "def partition_the_pdf_document(input_pdf: str) -> Dict[str, List[int]]:\n",
    "    \"\"\"\n",
    "    Partition a PDF document into distinct sections based on visual features using clustering.\n",
    "\n",
    "    Args:\n",
    "        input_pdf (str): The path to the input PDF file.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[int]]: A dictionary where keys are document names and values are lists of page numbers.\n",
    "    \"\"\"\n",
    "    global document  # Declare as global to access inside get_background_color\n",
    "    document = fitz.open(input_pdf)\n",
    "    feature_vectors = []\n",
    "    features_list = []\n",
    "    pages = []\n",
    "    header_texts = []\n",
    "    footer_texts = []\n",
    "    watermark_texts = []\n",
    "\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        features = get_visual_features(page)\n",
    "        features_list.append({'page': page_num + 1, **features})\n",
    "        header_texts.append(features['header_text'])\n",
    "        footer_texts.append(features['footer_text'])\n",
    "        watermark_texts.append(features['watermark_text'])\n",
    "        pages.append(page_num + 1)\n",
    "\n",
    "    # Save features to CSV\n",
    "    save_features_to_csv(features_list, 'page_features.csv')\n",
    "\n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer().fit(header_texts + footer_texts + watermark_texts)\n",
    "\n",
    "    # Create feature vectors\n",
    "    for features in features_list:\n",
    "        vector = feature_vectorize(features, vectorizer)\n",
    "        feature_vectors.append(vector)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    feature_vectors = np.array(feature_vectors)\n",
    "\n",
    "    # Determine the optimal number of clusters\n",
    "    num_clusters = determine_optimal_clusters(feature_vectors)\n",
    "    print(f\"Optimal number of clusters: {num_clusters}\")\n",
    "\n",
    "    # Perform clustering\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=0, n_init=10, max_iter=100).fit(feature_vectors)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Group pages by cluster labels\n",
    "    document_groups = defaultdict(list)\n",
    "    for page_num, label in zip(pages, labels):\n",
    "        document_groups[f\"Document {label + 1}\"].append(page_num)\n",
    "\n",
    "    return dict(document_groups)\n",
    "\n",
    "# Usage\n",
    "input_pdf: str = \"grouped_documents.pdf\"\n",
    "partitions: Dict[str, List[int]] = partition_the_pdf_document(input_pdf)\n",
    "print(f\"Partitions: {partitions}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
